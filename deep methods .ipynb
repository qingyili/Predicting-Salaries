{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('microdata_processed/train_train.csv')\n",
    "test = pd.read_csv('microdata_processed/train_test_set.csv')\n",
    "validation = pd.read_csv('microdata_processed/train_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full = pd.concat([train,test,validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51864, 195)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col = list(train.columns.values)\n",
    "\n",
    "x_col.remove('Unnamed: 0')\n",
    "x_col.remove('CASEID')\n",
    "x_col.remove('morethan60kyr')\n",
    "\n",
    "train_y=train['morethan60kyr']\n",
    "test_y = test['morethan60kyr']\n",
    "\n",
    "train_x = train[x_col]\n",
    "test_x = test[x_col]\n",
    "n_train = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   0, 161,   2, 158,  44,  45,  42, 179,  40,  99,  79,\n",
       "        27, 127, 149,  85, 125,  35,  46,  22, 175, 124, 148, 169, 140,\n",
       "        53,  69, 147, 131, 162, 151, 121, 114,  54,  58,  57, 115,  47,\n",
       "        61, 119, 141,  17, 142,  48, 145, 123, 177,  64,  28, 156, 118,\n",
       "        72, 116,  29,  71,  60, 187,  62, 120,  63, 181,  83, 122,  37,\n",
       "        39,  15, 184,  51,  68, 154,  23,  86, 165,  50, 143,  65,   5,\n",
       "        91,  55, 182,  74, 135, 112, 174, 163,  78, 146,   9,   6,  75,\n",
       "       153, 191,  30,  59,  18, 129, 138,  76,  34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30, n_jobs=-1,min_samples_split=5,max_features=50)\n",
    "rf.fit(train_x,train_y)\n",
    "rf.score(train_x,train_y)\n",
    "#rf.score(test_x,test_y)\n",
    "importance = rf.feature_importances_\n",
    "\n",
    "imp_arg = np.argsort(importance)\n",
    "imp_arg=imp_arg[::-1]\n",
    "\n",
    "top_k = 100\n",
    "imp_arg[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x[imp_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_x = test_x[imp_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normailize\n",
    "# x_min =  np.min(train_x,axis=0)\n",
    "# x_range = np.max(train_x,axis=0)-x_min\n",
    "# x_range = np.max(test_x,axis=0)-np.min(test_x,axis=0)\n",
    "# train_x = (train_x)/x_range\n",
    "# test_x = (test_x)/x_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FFNN(object):\n",
    "    def __init__(self,layer_size,n_feat, n_class):\n",
    "        self.x = tf.placeholder(tf.float32, shape = (None,n_feat), name = 'x')\n",
    "        self.y = tf.placeholder(tf.float32, shape = (None,n_class), name = 'y')\n",
    "        self.keep_prob = tf.placeholder(tf.float32,name = 'keep_prob')\n",
    "        \n",
    "\n",
    "        def layer (input_size, output_size, input_x, layer_num):\n",
    "             with tf.name_scope('hidden-layer_{}'.format(layer_num)):\n",
    "                W= tf.get_variable(\n",
    "                    \"W_{}\".format(layer_num),\n",
    "                    shape = [input_size,output_size],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "                b= tf.Variable(tf.zeros([output_size]),name='b_{}'.format(layer_num))\n",
    "                h= tf.nn.relu(tf.nn.xw_plus_b(input_x,W,b, name ='h_{}'.format(layer_num)))\n",
    "                h_drop = tf.nn.dropout(h, self.keep_prob)\n",
    "                return W,b,h_drop \n",
    "        \n",
    "        W,b,h = layer(n_feat, layer_size[0],self.x,1)\n",
    "        \n",
    "        for i in range(1,len(layer_size)-1):\n",
    "            W,b,h = layer(layer_size[i],layer_size[i+1],h,i+2)\n",
    "            \n",
    "        \n",
    "        with tf.name_scope('output'):\n",
    "            W= tf.get_variable(\n",
    "                \"output/W\",\n",
    "                shape = [layer_size[-1],n_class],\n",
    "                initializer = tf.contrib.layers.xavier_initializer())\n",
    "            b= tf.Variable(tf.constant(0.1, shape =[n_class], name =\"output/b\"))\n",
    "            scores =tf.nn.xw_plus_b(h,W,b, name =\"scores\")   \n",
    "            self.prediction=tf.argmax(scores, 1, name=\"predictions\")\n",
    "            self.probability = tf.nn.softmax(scores)\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(scores,self.y)\n",
    "            self.loss = tf.reduce_mean(losses)\n",
    "    \n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.prediction, tf.argmax(self.y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = FFNN([50], train_x.shape[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "learning_rate=tf.train.exponential_decay(0.001, global_step,7000, 0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(nn.loss)\n",
    "train_step= optimizer.apply_gradients(grads_and_vars, global_step= global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100 \n",
    "train_steps = np.floor(n_train/batch_size)*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    yy =np.zeros((y.shape[0],2))\n",
    "    yy[np.arange(y.shape[0]),y]=1\n",
    "    return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_acc_all():\n",
    "    test_yy = to_one_hot(test_y)\n",
    "    feed_dict = {nn.x:test_x,nn.y:test_yy, nn.keep_prob:1}\n",
    "    return nn.accuracy.eval(feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1000, train loss: 0.619397, train accuracy: 0.69\n",
      "step:2000, train loss: 0.560679, train accuracy: 0.74\n",
      "step:3000, train loss: 0.419442, train accuracy: 0.85\n",
      "step:4000, train loss: 0.493257, train accuracy: 0.78\n",
      "step:5000, train loss: 0.590729, train accuracy: 0.75\n",
      "step:6000, train loss: 0.470538, train accuracy: 0.77\n",
      "step:7000, train loss: 0.528445, train accuracy: 0.81\n",
      "step:8000, train loss: 0.526179, train accuracy: 0.77\n",
      "step:9000, train loss: 0.477775, train accuracy: 0.76\n",
      "step:10000, train loss: 0.519046, train accuracy: 0.77\n",
      "step:11000, train loss: 0.455281, train accuracy: 0.8\n",
      "step:12000, train loss: 0.452798, train accuracy: 0.79\n",
      "step:13000, train loss: 0.429788, train accuracy: 0.76\n",
      "step:14000, train loss: 0.443374, train accuracy: 0.77\n",
      "step:15000, train loss: 0.585689, train accuracy: 0.73\n",
      "step:16000, train loss: 0.445786, train accuracy: 0.81\n",
      "step:17000, train loss: 0.473191, train accuracy: 0.78\n",
      "step:18000, train loss: 0.47985, train accuracy: 0.82\n",
      "step:19000, train loss: 0.482775, train accuracy: 0.75\n",
      "step:20000, train loss: 0.569969, train accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "while step <train_steps:\n",
    "    for i in range(0,n_train,batch_size):\n",
    "        batch_x = train_x[i:i+batch_size]\n",
    "        batch_y = to_one_hot(train_y[i:i+batch_size])\n",
    "        \n",
    "        train_step.run(session=sess, feed_dict={nn.x: batch_x, nn.y: batch_y, nn.keep_prob: 0.5})\n",
    "        \n",
    "        if step%1000==0 and step!=0:\n",
    "            feed_dict={nn.x: batch_x, nn.y: batch_y, nn.keep_prob: 1}\n",
    "            train_loss,train_acc= sess.run([nn.loss,nn.accuracy], feed_dict= feed_dict)\n",
    "            print 'step:'+str(step)+ \", train loss: \"+str(train_loss)+ \", train accuracy: \"+str(train_acc)#+ ' test acc '+ str(test_acc_all())\n",
    "        step +=1\n",
    "    train_x, train_y = shuffle(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver.save(sess, 'nn_h_50', global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check the validation set \n",
    "validation = pd.read_csv('microdata_processed/train_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_y=train['morethan60kyr']\n",
    "validation_x = train[x_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_x=validation_x[imp_arg]\n",
    "validation_yy = to_one_hot(validation_y)\n",
    "feed_dict = {nn.x:validation_x,nn.y:validation_yy, nn.keep_prob:1}\n",
    "nn.accuracy.eval(feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('microdata_processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.set_index('CASEID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_col=list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['cma_Hamilton'] = np.zeros(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['cma_Halifax'] = np.zeros(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_test=test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y = nn.prediction.eval(feed_dict ={nn.x:test[x_col][imp_arg],nn.keep_prob:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['morethan60kyr']=test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds =test['morethan60kyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = preds.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv('test_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred['morethan60kyr'].astype('bool').to_csv('test_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
